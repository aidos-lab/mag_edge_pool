{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c58411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.utils import to_networkx\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, TopKPooling, GeneralConv\n",
    "from torch_geometric.nn import MLP\n",
    "from mag_edge_pool.src.make_splits import make_splits\n",
    "import json\n",
    "from torch.nn import PReLU\n",
    "from torch_geometric.nn import global_add_pool\n",
    "from mag_edge_pool.src.model import set_seed\n",
    "from mag_edge_pool.mag_edge_pool import mag_edge_pool_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3bb6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooling method: MagEdgePool\n",
      "Dataset: MUTAG\n",
      "Early stopping at epoch 52 for seed 41\n",
      "Early stopping at epoch 89 for seed 41\n",
      "Early stopping at epoch 53 for seed 41\n",
      "Early stopping at epoch 53 for seed 41\n",
      "Early stopping at epoch 123 for seed 41\n",
      "Early stopping at epoch 54 for seed 41\n",
      "Early stopping at epoch 89 for seed 41\n",
      "Early stopping at epoch 52 for seed 41\n",
      "Early stopping at epoch 54 for seed 41\n",
      "Early stopping at epoch 53 for seed 41\n",
      "Total time for 10 runs: 66.22 seconds\n",
      "Average Best Val Acc: 0.9118\n",
      "Std Best Test Acc: 0.0802\n",
      "Average Test Acc: 0.8673\n",
      "Experiment data saved to ./results/MUTAG/GeneralConv_MagEdgePool_MUTAG_stratified_41.json\n",
      "-----------------------------------------------------\n",
      "Pooling method: SpreadEdgePool\n",
      "Dataset: MUTAG\n",
      "Early stopping at epoch 52 for seed 41\n",
      "Early stopping at epoch 89 for seed 41\n",
      "Early stopping at epoch 53 for seed 41\n",
      "Early stopping at epoch 53 for seed 41\n",
      "Early stopping at epoch 123 for seed 41\n",
      "Early stopping at epoch 54 for seed 41\n",
      "Early stopping at epoch 89 for seed 41\n",
      "Early stopping at epoch 52 for seed 41\n",
      "Early stopping at epoch 54 for seed 41\n",
      "Early stopping at epoch 53 for seed 41\n",
      "Total time for 10 runs: 53.27 seconds\n",
      "Average Best Val Acc: 0.9118\n",
      "Std Best Test Acc: 0.0802\n",
      "Average Test Acc: 0.8673\n",
      "Experiment data saved to ./results/MUTAG/GeneralConv_SpreadEdgePool_MUTAG_stratified_41.json\n",
      "-----------------------------------------------------\n",
      "Pooling method: EdgePooling\n",
      "Dataset: MUTAG\n",
      "Early stopping at epoch 52 for seed 41\n",
      "Early stopping at epoch 53 for seed 41\n",
      "Early stopping at epoch 52 for seed 41\n",
      "Early stopping at epoch 91 for seed 41\n",
      "Early stopping at epoch 52 for seed 41\n",
      "Early stopping at epoch 56 for seed 41\n",
      "Early stopping at epoch 56 for seed 41\n",
      "Early stopping at epoch 54 for seed 41\n",
      "Early stopping at epoch 53 for seed 41\n",
      "Early stopping at epoch 54 for seed 41\n",
      "Total time for 10 runs: 113.14 seconds\n",
      "Average Best Val Acc: 0.9000\n",
      "Std Best Test Acc: 0.0902\n",
      "Average Test Acc: 0.8357\n",
      "Experiment data saved to ./results/MUTAG/GeneralConv_EdgePooling_MUTAG_stratified_41.json\n",
      "-----------------------------------------------------\n",
      "Pooling method: TopKPooling\n",
      "Dataset: MUTAG\n",
      "Early stopping at epoch 84 for seed 41\n",
      "Early stopping at epoch 81 for seed 41\n",
      "Early stopping at epoch 55 for seed 41\n",
      "Early stopping at epoch 54 for seed 41\n",
      "Early stopping at epoch 52 for seed 41\n",
      "Early stopping at epoch 64 for seed 41\n",
      "Early stopping at epoch 53 for seed 41\n",
      "Early stopping at epoch 103 for seed 41\n",
      "Early stopping at epoch 63 for seed 41\n",
      "Early stopping at epoch 71 for seed 41\n",
      "Total time for 10 runs: 55.92 seconds\n",
      "Average Best Val Acc: 0.9000\n",
      "Std Best Test Acc: 0.0940\n",
      "Average Test Acc: 0.8456\n",
      "Experiment data saved to ./results/MUTAG/GeneralConv_TopKPooling_MUTAG_stratified_41.json\n",
      "-----------------------------------------------------\n",
      "Pooling method: SAGPooling\n",
      "Dataset: MUTAG\n",
      "Early stopping at epoch 67 for seed 41\n",
      "Early stopping at epoch 95 for seed 41\n",
      "Early stopping at epoch 55 for seed 41\n",
      "Early stopping at epoch 75 for seed 41\n",
      "Early stopping at epoch 64 for seed 41\n",
      "Early stopping at epoch 64 for seed 41\n",
      "Early stopping at epoch 85 for seed 41\n",
      "Early stopping at epoch 90 for seed 41\n",
      "Early stopping at epoch 61 for seed 41\n",
      "Early stopping at epoch 70 for seed 41\n",
      "Total time for 10 runs: 57.05 seconds\n",
      "Average Best Val Acc: 0.9000\n",
      "Std Best Test Acc: 0.1365\n",
      "Average Test Acc: 0.7924\n",
      "Experiment data saved to ./results/MUTAG/GeneralConv_SAGPooling_MUTAG_stratified_41.json\n",
      "-----------------------------------------------------\n",
      "Pooling method: NoPooling\n",
      "Dataset: MUTAG\n",
      "Early stopping at epoch 92 for seed 41\n",
      "Early stopping at epoch 54 for seed 41\n",
      "Early stopping at epoch 51 for seed 41\n",
      "Early stopping at epoch 54 for seed 41\n",
      "Early stopping at epoch 92 for seed 41\n",
      "Early stopping at epoch 52 for seed 41\n",
      "Early stopping at epoch 73 for seed 41\n",
      "Early stopping at epoch 54 for seed 41\n",
      "Early stopping at epoch 55 for seed 41\n",
      "Early stopping at epoch 76 for seed 41\n",
      "Total time for 10 runs: 39.10 seconds\n",
      "Average Best Val Acc: 0.9000\n",
      "Std Best Test Acc: 0.0816\n",
      "Average Test Acc: 0.8354\n",
      "Experiment data saved to ./results/MUTAG/GeneralConv_NoPooling_MUTAG_stratified_41.json\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "max_nodes = 10000\n",
    "max_degree = 10000\n",
    "dataset_name = \"MUTAG\"\n",
    "metric = \"diffusion_distance\"\n",
    "ratio = 0.5\n",
    "model_name = \"GeneralConv\"\n",
    "splits = \"stratified\"\n",
    "early_stop_patience = 50\n",
    "tolerance = 1e-6\n",
    "runs=10\n",
    "learning_rate = 5e-4\n",
    "patience = early_stop_patience\n",
    "batch_size = 32\n",
    "ratio = 0.5\n",
    "n_hidden = 64\n",
    "seeds = [41] \n",
    "seed = 41\n",
    "\n",
    "for method in [\"MagEdgePool\",\"SpreadEdgePool\", \"EdgePooling\", \"TopKPooling\",  \"SAGPooling\", \"NoPooling\"]:\n",
    "    print(f\"Pooling method: {method}\")\n",
    "    print(f\"Dataset: {dataset_name}\")\n",
    "    \n",
    "    data_path = f\"../data/{dataset_name}/{method}/\"\n",
    "    pooling_method = method\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "\n",
    "    ### Load the dataset\n",
    "    if dataset_name in [\"DD\", \"COLLAB\", \"IMDB-BINARY\", \"IMDB-MULTI\", \"REDDIT-BINARY\", \"REDDIT-MULTI-5K\"]:\n",
    "        dataset_sparse = TUDataset(root=data_path, name=dataset_name, pre_filter=lambda data: data.num_nodes <= max_nodes, transform=T.Compose([T.OneHotDegree(max_degree)]), use_node_attr=True)\n",
    "    else:\n",
    "        dataset_sparse = TUDataset(root=data_path, name=dataset_name, pre_filter=lambda data: data.num_nodes <= max_nodes, use_node_attr=True)\n",
    "\n",
    "    num_classes = dataset_sparse.num_classes\n",
    "    in_channels = dataset_sparse.num_features\n",
    "    num_features = dataset_sparse.num_features\n",
    "\n",
    "    ### Determine the method for magnitude computation based on the pooling method\n",
    "    if \"Mag\" in method:\n",
    "        mag_method = \"cholesky\"\n",
    "    elif \"Spread\" in method:\n",
    "        mag_method = \"spread\"\n",
    "    \n",
    "    ### Define the GNN using PyTorch Geometric\n",
    "    class MainModelTorch(torch.nn.Module):\n",
    "        def __init__(self, in_channels, hidden_channels, out_channels, num_classes, pool):\n",
    "            super(MainModelTorch, self).__init__()\n",
    "            self.pre = MLP(in_channels=in_channels, hidden_channels=hidden_channels, num_layers=2, out_channels=hidden_channels)\n",
    "            self.conv1 = GeneralConv(hidden_channels, hidden_channels, aggr=\"add\")\n",
    "            self.bn = PReLU()\n",
    "            self.bn2 = PReLU()\n",
    "            self.conv2 = GeneralConv(hidden_channels*2, hidden_channels, aggr=\"add\")\n",
    "            \n",
    "            self.post = MLP(in_channels=out_channels*3, hidden_channels=hidden_channels, out_channels=num_classes, num_layers=2)\n",
    "\n",
    "            self.pool = pool\n",
    "\n",
    "        def forward(self, data):\n",
    "            if (\"MagEdgePool\" in method) or (\"SpreadEdgePool\" in method):\n",
    "                cluster = data.cluster\n",
    "            x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "            x = self.pre(x)\n",
    "\n",
    "            x = self.bn(x)\n",
    "\n",
    "            gnn1_out = self.conv1(x, edge_index)\n",
    "            x = torch.cat([gnn1_out, x], dim=-1)\n",
    "\n",
    "            if (\"MagEdgePool\" in method) or (\"SpreadEdgePool\" in method):\n",
    "                x, edge_index, batch, unpool = self.pool(x, edge_index, batch=batch, cluster=cluster)\n",
    "            elif method == \"TopKPooling\" or method == \"SAGPooling\":\n",
    "                x, edge_index, _, batch, _, _ = self.pool(x, edge_index, batch=batch)\n",
    "            else:\n",
    "                x, edge_index, batch, unpool = self.pool(x, edge_index, batch=batch)\n",
    "            \n",
    "            x = self.bn2(x)\n",
    "            \n",
    "            gnn2_out = self.conv2(x, edge_index)\n",
    "            x = torch.cat([gnn2_out, x], dim=-1)\n",
    "            \n",
    "            x = global_add_pool(x, batch)\n",
    "            \n",
    "            x = self.post(x)\n",
    "            \n",
    "            return x\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    ### Preprocess the dataset with the specified pooling method\n",
    "    if (\"MagEdgePool\" in pooling_method) or (\"SpreadEdgePool\" in pooling_method):\n",
    "        data_list = mag_edge_pool_transform(dataset_sparse, pooling_method, ratio, metric, mag_method)\n",
    "\n",
    "    ### Set random seed for reproducibility and shuffle the dataset\n",
    "    set_seed(seed)\n",
    "    if (\"MagEdgePool\" in pooling_method) or (\"SpreadEdgePool\" in pooling_method):\n",
    "        dataset_sparse, perm = dataset_sparse.shuffle(return_perm=True)\n",
    "        data_list = [data_list[p] for p in perm]\n",
    "    else:\n",
    "        dataset_sparse = dataset_sparse.shuffle()\n",
    "    \n",
    "\n",
    "    ### Train and evaluate the model across multiple runs using different cross-validation splits\n",
    "    best_val_accs = []\n",
    "    best_test_accs = []\n",
    "\n",
    "    for run in range(runs):\n",
    "        num_total = len(dataset_sparse)\n",
    "\n",
    "        labels = np.array([data.y.item() for data in dataset_sparse])\n",
    "\n",
    "        split_list = make_splits(np.array([int(ni) for ni in range(num_total)]), labels, outer_k=10, inner_k=None, holdout_test_size=0.1, seed=seed)\n",
    "        idx_tr, idx_va, idx_te = split_list[run][0], split_list[run][1], split_list[run][2]\n",
    "\n",
    "        if (\"MagEdgePool\" in pooling_method) or (\"SpreadEdgePool\" in pooling_method):\n",
    "            train_dataset = [data_list[i] for i in idx_tr]\n",
    "            val_dataset = [data_list[i] for i in idx_va]\n",
    "            test_dataset = [data_list[i] for i in idx_te]\n",
    "        else:\n",
    "            train_dataset = dataset_sparse[idx_tr]\n",
    "            val_dataset = dataset_sparse[idx_va]\n",
    "            test_dataset = dataset_sparse[idx_te]\n",
    "            \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        valid_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        if (\"MagEdgePool\" in pooling_method) or (\"SpreadEdgePool\" in pooling_method):\n",
    "            from mag_edge_pool.mag_edge_pool import MagEdgePooling \n",
    "            pool = MagEdgePooling(n_hidden*2)\n",
    "        elif pooling_method == \"TopKPooling\":\n",
    "            pool = TopKPooling(n_hidden*2, ratio=0.5)\n",
    "        elif pooling_method == \"EdgePooling\":\n",
    "            from torch_geometric.nn.pool import EdgePooling\n",
    "            pool = EdgePooling(n_hidden*2)\n",
    "        elif pooling_method == \"SAGPooling\":\n",
    "            from torch_geometric.nn.pool import SAGPooling\n",
    "            pool = SAGPooling(n_hidden*2, ratio=0.5)\n",
    "        elif pooling_method == \"NoPooling\":\n",
    "            def NoPooling(x, edge_index, batch, cluster=None):\n",
    "                return x, edge_index, batch, None\n",
    "            pool = NoPooling\n",
    "            ratio = 1\n",
    "        else:\n",
    "            raise ValueError(f\"Not implemented yet: {pooling_method}\")\n",
    "\n",
    "        model = MainModelTorch(in_channels=dataset_sparse.num_features, hidden_channels=n_hidden, out_channels=n_hidden, num_classes=dataset_sparse.num_classes, pool=pool).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        def train():\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            for data in train_loader:\n",
    "                data = data.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = model(data)\n",
    "                loss = F.nll_loss(out, data.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item() * data.num_graphs\n",
    "            return total_loss / len(train_loader.dataset)\n",
    "\n",
    "        def test(loader):\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            for data in loader:\n",
    "                data = data.to(device)\n",
    "                out = model(data)\n",
    "                pred = out.argmax(dim=1)\n",
    "                correct += (pred == data.y).sum().item()\n",
    "            return correct / len(loader.dataset)\n",
    "\n",
    "        model = MainModelTorch(in_channels=dataset_sparse.num_features, hidden_channels=n_hidden, out_channels=n_hidden, num_classes=dataset_sparse.num_classes, pool=pool).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "        \n",
    "        best_val_acc = 0\n",
    "        epochs_no_improve = 0\n",
    "        for epoch in range(1, 201):\n",
    "            loss = train()\n",
    "            val_acc = test(valid_loader)\n",
    "            test_acc = test(test_loader)\n",
    "            if val_acc > best_val_acc + tolerance:\n",
    "                best_val_acc = val_acc\n",
    "                best_test_acc = test_acc\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "            if epochs_no_improve >= early_stop_patience:\n",
    "                print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "                break\n",
    "        \n",
    "        best_val_accs.append(best_val_acc)\n",
    "        best_test_accs.append(best_test_acc)\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "    print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "    print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')\n",
    "\n",
    "    ### Save experiment data to a JSON file\n",
    "    experiment_data = {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"method\": method,\n",
    "        \"model\": model_name,\n",
    "        \"experiment\": \"graph_classification\",\n",
    "        \"runs\": runs,\n",
    "        \"split_strategy\": \"stratified\",\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"es_patience\": patience,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"seeds\": seeds,\n",
    "        \"loss\": \"categorical_crossentropy\",\n",
    "        \"results\": {\n",
    "            \"accuracy\": [float(r) for r in best_test_accs]\n",
    "        },\n",
    "        \"ratio\": ratio\n",
    "    }\n",
    "\n",
    "    log_dir = f\"./results/{dataset_name}/\"\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    json_file_path = os.path.join(log_dir, f\"{model_name}_{method}_{dataset_name}_{splits}_{seed}.json\")\n",
    "\n",
    "    with open(json_file_path, \"w\") as json_file:\n",
    "        json.dump(experiment_data, json_file, indent=4)\n",
    "    print(f\"Experiment data saved to {json_file_path}\")\n",
    "    print(\"-----------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mag-edge-pool-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
